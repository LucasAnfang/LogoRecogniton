Instagram Scraper for Logo Detection Setup:
	Initial Project: https://github.com/rarcega/instagram-scraper
	Run these commands in terminal:
	INSTALLATION:
		sudo chown -R $USER /Library/Python/2.7
		pip install instagram-scraper
		pip install instagram-scraper --upgrade
	USE:
	TRAINING:
		instagram-scraper --t hashTagOne --maximum MAX_NUM_IMAGES
			1) gets images for a related hashtag (this all uses the predefined inputs of forked repo)
			2) The analyst sifts through the images in the directory making sure all contain the logo
		training-directory-uploader —-t hashTagOne —-brand_name —-dir DirPath 
			3) using the image directory, loop the images and create a list of dictionary objects with keys: 
			id and serialized_image
			4) we can worry about compression later but for now call into the network file system uploader with 			the proper brand name’s (given as arg) training directory

	OPERATIONAL:
		ig-scraper-to-operational-directory—uploader —-t “hashTagOne|hashTagTwo” —-b BRAND 
		--maximum_images MAX_NUM_IMAGES
			1) use/make functions in the instagram-scraper to get all the images with the provided list of 				hashtags. Instead of saving the images make a function in instagram-scraper that will output the 
			serialized list of dictionary objects with all the post metadata plus fields that bryce will populate 			upon classification
			2) upload this text to the network file system to the proper brand name’s (given as arg) operational 			directory


CNTK (Microsoft's ML Opensource competitor of TensorFlow)

TensorFlow Notes
Links: https://www.tensorflow.org/get_started/get_started
Terms:
	- Virtualenv: a tool created to create isolated Python environments (main focus is to solve issues with dependencies and versions)
	- A tensor consists of a set of primitive values shaped into an array of any number of dimensions
	- A tensor's rank is its number of dimension
	- A bottleneck is an informal term we often use for the layer just before the final output layer that actually does the classification
		- Every image is reused multiple times during training
	Result:
		- The training accuracy shows the percentage of the images used in the current training batch that were labeled with the correct class.
		- Validation accuracy: The validation accuracy is the precision (percentage of correctly-labelled images) on a randomly-selected group of images from a different set.
		- Cross entropy is a loss function that gives a glimpse into how well the learning process is progressing (lower numbers are better here).
		Note: 
		- If the training accuracy is high but the validation accuracy remains low, that means the network is overfitting, and the network is memorizing particular features in the training images that don't help it classify images more generally.

Setup:
	$ sudo easy_install pip
 	$ sudo pip install --upgrade virtualenv 

 	$ virtualenv --system-site-packages targetDirectory # (Python 2.7)
 	$ source ~/tensorflow/bin/activate      # If using bash

 	$ pip install Pillow
 	$ pip install sklearn 

 Maintainance of library
 	(tensorflow)$ easy_install -U pip
 	(tensorflow)$ pip install --upgrade tensorflow      # for Python 2.7
 	$ pip install --upgrade tfBinaryURL   # Python 2.7 (if prev 2 fail)

General Notes:
	All TensorFlow APIs are built on top of TensorFlow Core

Great Walkthrough on MobileNet Retrain without Bazel: https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0



Azure Storage with Python 
	Link: https://github.com/Azure/azure-storage-python
	https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior

Virtual Env (hacky fix)
python -m virtualenv custom-env-name